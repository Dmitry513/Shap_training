{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820d0d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import shap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5dc5571",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed52cf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eaa55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383bf4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a87709",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694aabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "#     Replace the last fully-connected layer\n",
    "#     Parameters of newly constructed modules have requires_grad=True by default\n",
    "resnet18.fc = nn.Linear(512, 10) # assuming that the fc7 layer has 512 neurons, otherwise change it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c09cbb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18.type(torch.cuda.FloatTensor)\n",
    "resnet18.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "optimizer = torch.optim.Adam(resnet18.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78c66d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs, step_size):    \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.5)\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train() # Enter train mode\n",
    "\n",
    "            loss_accum = 0\n",
    "            correct_samples = 0\n",
    "            total_samples = 0\n",
    "            for i_step, (x, y) in enumerate(train_loader):          \n",
    "                x_gpu = x.to(device)\n",
    "                if type(y) == int:\n",
    "                    y = torch.tensor(y.float32)\n",
    "    #             y = y.unsqueeze(1)\n",
    "\n",
    "                y_gpu = y.to(device)\n",
    "                prediction = model(x_gpu)    \n",
    "                loss_value = loss(prediction, y_gpu)\n",
    "                optimizer.zero_grad()\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                _, indices = torch.max(prediction, 1)\n",
    "                correct_samples += torch.sum(indices == y_gpu)\n",
    "                total_samples += y.shape[0]\n",
    "\n",
    "                loss_accum += loss_value\n",
    "\n",
    "            ave_loss = loss_accum / i_step\n",
    "            train_accuracy = float(correct_samples) / total_samples\n",
    "            val_accuracy = compute_accuracy(model, val_loader)\n",
    "\n",
    "            loss_history.append(float(ave_loss))\n",
    "            train_history.append(train_accuracy)\n",
    "            val_history.append(val_accuracy)\n",
    "\n",
    "            print(f\"Average loss: {ave_loss:.3f}, Train accuracy: {train_accuracy:.3f}  | Test accuracy: {val_accuracy:.3f}\")\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    return loss_history, train_history, val_history\n",
    "        \n",
    "def compute_accuracy(model, loader):\n",
    "    \"\"\"\n",
    "    Computes accuracy on the dataset wrapped in a loader\n",
    "    \n",
    "    Returns: accuracy as a float value between 0 and 1\n",
    "    \"\"\"\n",
    "    model.eval() # Evaluation mode\n",
    "    \n",
    "    total_samples = 0\n",
    "    correct_samples = 0\n",
    "    for x, y in loader:\n",
    "        x_gpu = x.to(device)\n",
    "        if type(y) == int:\n",
    "            y = torch.tensor(y.float32)\n",
    "        y_gpu = y.to(device)\n",
    "        prediction = model(x_gpu)\n",
    "        indices = torch.argmax(prediction, 1)\n",
    "        correct_samples += torch.sum(indices == y_gpu)\n",
    "        total_samples += y_gpu.shape[0]\n",
    "    \n",
    "    return float(correct_samples) / total_samples\n",
    "\n",
    "def get_predictions(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    target = []\n",
    "    for x, y in loader:\n",
    "        y = y.unsqueeze(1)\n",
    "        x_gpu = x.to(device)\n",
    "        prediction = model(x_gpu)\n",
    "        preds.append(prediction.cpu().detach().numpy())\n",
    "        target.append(y)\n",
    "    preds = np.concatenate(preds, axis=0).reshape(-1)\n",
    "    target = np.concatenate(target, axis=0).reshape(-1)\n",
    "    return target, preds\n",
    "\n",
    "    \n",
    "def compute_scores(model, loader):\n",
    "    target, preds = get_predictions(model, loader)\n",
    "    r2 = compute_r2(target, preds)\n",
    "    mae = mean_absolute_error(target, preds)\n",
    "    return r2, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b7db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 2.247, Train accuracy: 0.184  | Test accuracy: 0.331\n",
      "Average loss: 1.895, Train accuracy: 0.304  | Test accuracy: 0.381\n",
      "Average loss: 1.651, Train accuracy: 0.402  | Test accuracy: 0.492\n",
      "Average loss: 1.497, Train accuracy: 0.462  | Test accuracy: 0.521\n",
      "Average loss: 1.375, Train accuracy: 0.512  | Test accuracy: 0.522\n",
      "Average loss: 1.287, Train accuracy: 0.546  | Test accuracy: 0.603\n",
      "Average loss: 1.204, Train accuracy: 0.576  | Test accuracy: 0.621\n",
      "Average loss: 1.153, Train accuracy: 0.597  | Test accuracy: 0.568\n",
      "Average loss: 1.115, Train accuracy: 0.613  | Test accuracy: 0.611\n",
      "Average loss: 1.078, Train accuracy: 0.625  | Test accuracy: 0.605\n",
      "Average loss: 1.064, Train accuracy: 0.632  | Test accuracy: 0.615\n",
      "Average loss: 1.079, Train accuracy: 0.624  | Test accuracy: 0.600\n",
      "Average loss: 1.033, Train accuracy: 0.641  | Test accuracy: 0.635\n",
      "Average loss: 0.996, Train accuracy: 0.656  | Test accuracy: 0.630\n"
     ]
    }
   ],
   "source": [
    "loss_history, train_history, val_history = train_model(resnet18, trainloader, testloader, loss, optimizer, 20, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d94e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(resnet18.state_dict(), 'Torch_models/resnet18.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f17edde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18.load_state_dict(torch.load('Torch_models/resnet18.pt',device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09372170",
   "metadata": {},
   "source": [
    "## Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5278ca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "explset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                       download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "113c1c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45ff8aef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11376/2382623696.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# here we explain two images using 500 evaluations of the underlying model to estimate the SHAP values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m shap_values = explainer(np.array(explset.__getitem__(8)[0].getdata()).reshape(32, 32, 3)[np.newaxis, :].astype('float32'), \n\u001b[0m\u001b[0;32m     26\u001b[0m                         max_evals=400, batch_size=500, outputs=shap.Explanation.argsort.flip[:10])\n",
      "\u001b[1;32mD:\\Programs\\anaconda3\\lib\\site-packages\\shap\\explainers\\_partition.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \"\"\" Explain the output of the model on the given arguments.\n\u001b[0;32m    134\u001b[0m         \"\"\"\n\u001b[1;32m--> 135\u001b[1;33m         return super().__call__(\n\u001b[0m\u001b[0;32m    136\u001b[0m             \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfixed_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_bounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror_bounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\anaconda3\\lib\\site-packages\\shap\\explainers\\_explainer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrow_args\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" explainer\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             row_result = self.explain_row(\n\u001b[0m\u001b[0;32m    259\u001b[0m                 \u001b[1;33m*\u001b[0m\u001b[0mrow_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmain_effects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain_effects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_bounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror_bounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\anaconda3\\lib\\site-packages\\shap\\explainers\\_partition.py\u001b[0m in \u001b[0;36mexplain_row\u001b[1;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, fixed_context, *row_args)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;31m# if not fixed background or no base value assigned then compute base value for a row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_curr_base_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fixed_background\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_curr_base_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm00\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# the zero index param tells the masked model what the baseline is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[0mf11\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mm00\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\anaconda3\\lib\\site-packages\\shap\\utils\\_masked_model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_full_masking_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_full_masking_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\anaconda3\\lib\\site-packages\\shap\\utils\\_masked_model.py\u001b[0m in \u001b[0;36m_full_masking_call\u001b[1;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mjoined_masked_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stack_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mall_masked_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mjoined_masked_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m             \u001b[0m_assert_output_input_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoined_masked_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mall_outputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\anaconda3\\lib\\site-packages\\shap\\models\\_model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# python function to get model output; replace this function with your own model function.\n",
    "resnet18.eval()\n",
    "def f(x):\n",
    "#     print(x.shape)\n",
    "    x = x.reshape(-1, 3, 32, 32)\n",
    "    rez = []\n",
    "    for img in x:\n",
    "#         print(img.shape)\n",
    "        tmp = torch.from_numpy(img).float()\n",
    "        tmp = normalization(tmp)\n",
    "        x_gpu = tmp.to(device)\n",
    "        x_gpu = torch.unsqueeze(x_gpu, 0)\n",
    "        return resnet18(x_gpu)\n",
    "        rez.append(torch.softmax(resnet18(x_gpu)).cpu().detach().numpy())\n",
    "    return np.concatenate(rez, axis=0)\n",
    "\n",
    "# define a masker that is used to mask out partitions of the input image.\n",
    "masker = shap.maskers.Image(\"inpaint_telea\", (32, 32, 3))\n",
    "\n",
    "\n",
    "# create an explainer with model and image masker\n",
    "explainer = shap.Explainer(f, masker, output_names=classes)\n",
    "\n",
    "# here we explain two images using 500 evaluations of the underlying model to estimate the SHAP values\n",
    "shap_values = explainer(np.array(explset.__getitem__(8)[0].getdata()).reshape(32, 32, 3)[np.newaxis, :].astype('float32'), \n",
    "                        max_evals=400, batch_size=500, outputs=shap.Explanation.argsort.flip[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509e865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output with shap values\n",
    "shap.image_plot(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "227a28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.array(explset.__getitem__(6)[0].getdata()).reshape(32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "85fa87ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[164, 206,  84],\n",
       "         [105, 140,  61],\n",
       "         [118, 148, 101],\n",
       "         ...,\n",
       "         [109, 147,  73],\n",
       "         [108, 147,  69],\n",
       "         [ 91, 129,  57]],\n",
       "\n",
       "        [[167, 213,  84],\n",
       "         [116, 160,  49],\n",
       "         [ 72, 109,  43],\n",
       "         ...,\n",
       "         [105, 142,  79],\n",
       "         [105, 142,  72],\n",
       "         [ 89, 127,  57]],\n",
       "\n",
       "        [[140, 191,  65],\n",
       "         [142, 193,  66],\n",
       "         [119, 163,  79],\n",
       "         ...,\n",
       "         [104, 139,  84],\n",
       "         [ 84, 120,  58],\n",
       "         [ 78, 115,  49]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[139, 148,  81],\n",
       "         [142, 155,  74],\n",
       "         [135, 156,  72],\n",
       "         ...,\n",
       "         [ 89, 134,  28],\n",
       "         [ 97, 148,  24],\n",
       "         [126, 176,  49]],\n",
       "\n",
       "        [[163, 157,  85],\n",
       "         [153, 164,  82],\n",
       "         [146, 164,  90],\n",
       "         ...,\n",
       "         [ 85, 130,  19],\n",
       "         [ 98, 148,  27],\n",
       "         [127, 178,  48]],\n",
       "\n",
       "        [[183, 153, 102],\n",
       "         [176, 182, 116],\n",
       "         [154, 154, 100],\n",
       "         ...,\n",
       "         [ 94, 134,  29],\n",
       "         [ 91, 133,  26],\n",
       "         [122, 170,  44]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6bdbbf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23d57d9afd0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "plt.imshow(np.array(explset.__getitem__(6)[0].getdata()).reshape(32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "be0976b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3329be18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3, 32, 32])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(a[0], 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27a33cc0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r = f(np.array(explset.__getitem__(111)[0].getdata()).reshape(32,32,3)[np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bb7697e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-39688.0352, -52476.5234, -47066.0391, -41027.1914, -45766.4102,\n",
       "         -45686.1289, -48292.2773, -40075.9180, -47280.7188, -43033.6328]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d037a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch(ten), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "855b4eff",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (Temp/ipykernel_13588/1591302973.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\79099\\AppData\\Local\\Temp/ipykernel_13588/1591302973.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    np.array(explset.__getitem__(6)[0].getdata()\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "np.array(explset.__getitem__(6)[0].getdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa763cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[164., 206.,  84., ..., 163., 140., 169.],\n",
       "         [116., 154., 196., ..., 243., 110., 203.],\n",
       "         [243.,  97., 188., ...,  91., 129.,  57.],\n",
       "         ...,\n",
       "         [ 96., 152., 163., ...,  92., 118.,  68.],\n",
       "         [ 55.,  92.,  37., ...,  29.,  93., 153.],\n",
       "         [ 41., 124., 177., ...,  89., 149.,  56.]],\n",
       "\n",
       "        [[117., 137., 171., ..., 111., 142.,  79.],\n",
       "         [ 56.,  91.,  33., ...,  40., 122., 178.],\n",
       "         [ 67., 146., 197., ...,  82., 155.,  69.],\n",
       "         ...,\n",
       "         [ 52.,  39.,  44., ...,  91.,  40., 103.],\n",
       "         [149.,  55., 117., ..., 143., 183.,  75.],\n",
       "         [198., 205., 208., ...,  75.,  23.,  21.]],\n",
       "\n",
       "        [[ 24.,  17.,  20., ..., 119.,  47., 139.],\n",
       "         [187.,  88., 115., ..., 161., 197., 107.],\n",
       "         [195., 203., 209., ...,  53.,  44.,  56.],\n",
       "         ...,\n",
       "         [183., 153., 102., ...,  71., 110.,  93.],\n",
       "         [ 67., 118., 128., ..., 169.,  83., 152.],\n",
       "         [192., 106., 157., ..., 122., 170.,  44.]]]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(explset.__getitem__(6)[0].getdata()).reshape(3, 32, 32)[np.newaxis, :].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0967b94d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
